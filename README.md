# Simple-Machine-Learning-Framework

## Overview

This project implements a simple machine learning framework that mimics the behavior of real-world ML frameworks like PyTorch, TensorFlow, and JAX. The goal is to understand how deep learning frameworks work under the hood by implementing fundamental components manually.

## Features

- **Custom Neural Network Components**:
  - Linear Layer
  - Sequential Layer
  - Tanh Activation Function
  - Softmax + Cross-Entropy Loss
- **Training on Synthetic Data**:
  - Uses a two-class spiral dataset for model evaluation.
- **Backpropagation & Gradient Descent**:
  - Implements forward and backward passes manually.


## Model Architecture

The implemented neural network consists of:

- **Input Layer**: Takes in the 2D spiral dataset.
- **Hidden Layers**: Fully connected layers with Tanh Activation.
- **Output Layer**: Uses Softmax + Cross-Entropy Loss for classification.

## Evaluation

- **Training Loss vs Epochs**
- **Decision Boundary Visualization**
- **Effect of Activation Functions**


This project is open-source and available under the **MIT License**.

